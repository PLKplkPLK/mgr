{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148a1be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\mgr\\.venv_windows\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torch import tensor\n",
    "from torchvision.transforms import transforms, InterpolationMode\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01fab5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFPATH = 'models'\n",
    "BACKBONE = \"vit_large_patch14_dinov2.lvd142m\"\n",
    "DFVIT_WEIGHTS = os.path.join(DFPATH, 'deepfaune-vit_large_patch14_dinov2.lvd142m.v4.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd8d28f",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "661f024c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.read_csv('../megadetector_results.csv', index_col=0)\n",
    "images['image_path'] = '../' + images['image_path']\n",
    "images['bbox'] = images[\"bbox\"].apply(\n",
    "    lambda b: ast.literal_eval(b) if isinstance(b, str) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13fe62d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vit_large_patch14_dinov2.lvd142m, in resolution 476x476\n",
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 20\n",
    "CROP_SIZE = 476  # default 182, has to be divisible by 14, 280? TODO\n",
    "\n",
    "class_labels = [\n",
    "    'bison', 'badger', 'ibex', 'beaver', 'red deer', 'golden jackal', 'chamois',\n",
    "    'cat', 'goat', 'roe deer', 'dog', 'raccoon dog', 'fallow deer', 'squirrel',\n",
    "    'moose', 'equid', 'genet', 'wolverine', 'hedgehog', 'lagomorph', 'wolf',\n",
    "    'otter', 'lynx', 'marmot', 'micromammal', 'mouflon', 'sheep', 'mustelid',\n",
    "    'bird', 'bear', 'porcupine', 'nutria', 'muskrat', 'raccoon', 'fox', 'reindeer',\n",
    "    'wild boar', 'cow'\n",
    "]\n",
    "\n",
    "\n",
    "def crop_normalized_bbox(img: Image.Image, bbox: list[float]):\n",
    "    \"\"\"\n",
    "    | img: PIL.Image opened image\n",
    "    | bbox: list [x, y, w, h], normalized 0-1\n",
    "    | returns cropped PIL.Image\n",
    "    \"\"\"\n",
    "    W, H = img.size\n",
    "    x, y, w, h = bbox\n",
    "\n",
    "    left = int(x * W)\n",
    "    top = int(y * H)\n",
    "    right = int((x + w) * W)\n",
    "    bottom = int((y + h) * H)\n",
    "\n",
    "    return img.crop((left, top, right, bottom))\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self):\n",
    "        self.model = Model()\n",
    "        self.model.loadWeights(DFVIT_WEIGHTS)\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize(\n",
    "                size=(CROP_SIZE, CROP_SIZE),\n",
    "                interpolation=InterpolationMode.BICUBIC,\n",
    "                antialias=None\n",
    "            ),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=tensor([0.4850, 0.4560, 0.4060]),\n",
    "                std=tensor([0.2290, 0.2240, 0.2250]))]\n",
    "            )\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "\n",
    "    def predictOnBatch(self, pil_images: list[Image.Image],\n",
    "                       withsoftmax=True)-> np.ndarray:\n",
    "        tensors = [self.transforms(im) for im in pil_images]\n",
    "        batch = torch.stack(tensors).to(self.device)  # (B, C, H, W)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            outputs = self.model.predict(batch, withsoftmax=withsoftmax)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.base_model = timm.create_model(\n",
    "            BACKBONE, pretrained=False,\n",
    "            num_classes=len(class_labels),\n",
    "            dynamic_img_size=True\n",
    "        )\n",
    "        print(f\"Using {BACKBONE}, in resolution {CROP_SIZE}x{CROP_SIZE}\")\n",
    "\n",
    "        self.n_classes = len(class_labels)\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        print(\"Using CUDA\" if torch.cuda.is_available() else \"Using CPU\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.base_model(input)  \n",
    "\n",
    "    def predict(self, x, withsoftmax=True):\n",
    "        self.eval()\n",
    "        with torch.inference_mode():\n",
    "            x = x.to(self.device)\n",
    "            logits = self.forward(x)\n",
    "            return logits.softmax(dim=1) if withsoftmax else logits\n",
    "\n",
    "    def loadWeights(self, path):\n",
    "        try:\n",
    "            params = torch.load(\n",
    "                path, map_location=self.device, weights_only=False\n",
    "            )\n",
    "            args = params['args']\n",
    "\n",
    "            if self.n_classes != args['num_classes']:\n",
    "                raise Exception(\n",
    "                    f\"Checkpoint has {args['num_classes']} classes, but\"\n",
    "                    \"model expects {self.n_classes}\"\n",
    "                )\n",
    "            self.load_state_dict(params['state_dict'])\n",
    "        except Exception as e:\n",
    "            print(f\"Can't load checkpoint model :\\n {str(e)}\", file=sys.stderr)\n",
    "            raise e\n",
    "\n",
    "classifier = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93552c6c",
   "metadata": {},
   "source": [
    "### The loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "823f17d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4431/18107 [34:40<2:02:53,  1.85it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/1/2022-11-18 05-58-30.JPG: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 4435/18107 [34:40<1:01:17,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/1/2022-11-18 05-59-31.JPG: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 4458/18107 [34:52<55:43,  4.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/1/2022-11-18 06-08-54.JPG: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 4460/18107 [34:52<41:36,  5.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/1/2022-11-18 06-11-45.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/1/2022-11-18 06-11-53.JPG: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 4518/18107 [35:25<2:11:51,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-20 20-37-25.JPG: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 4535/18107 [35:28<39:44,  5.69it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-21 21-58-04.JPG: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 4554/18107 [35:39<41:07,  5.49it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-23 20-44-24.JPG: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 4687/18107 [36:54<2:42:45,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-24 19-47-26.JPG: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 4695/18107 [36:55<49:01,  4.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-24 20-03-00.JPG: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 4717/18107 [37:06<1:03:59,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-24 21-01-18.JPG: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 4727/18107 [37:08<36:54,  6.04it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-24 21-07-20.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-24 21-11-14.JPG: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5111/18107 [40:06<37:03,  5.85it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/10_ŁUPKÓW/R/Późna jesień/1/2022-11-14 22-12-20.JPG: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 5662/18107 [44:09<40:47,  5.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/11_ZUBEŃSKO/B/Wczesna jesień/3/2022-10-02 21-42-15.JPG: broken data stream when reading image file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 8122/18107 [1:03:11<28:00,  5.94it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/16_HUTA_KOMOROWSKA/B/Lato/1/2023-07-08 08-12-33.JPG: image file is truncated (22 bytes not processed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18107/18107 [3:52:32<00:00,  1.30it/s]      \n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({'image': [], 'detected_animal': [], 'confidence': []})\n",
    "batch = []\n",
    "paths = []\n",
    "\n",
    "for _, row in tqdm(images.iterrows(), total=len(images)):\n",
    "    image_path = row['image_path']\n",
    "\n",
    "    category = row['category']\n",
    "    if category != 1:\n",
    "        results.loc[len(results)] = [image_path, 'empty', 0]\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        cropped_image = crop_normalized_bbox(image, row['bbox'])\n",
    "    except Exception as e:\n",
    "        print(f'Error in image {image_path}: {e}')\n",
    "        continue\n",
    "\n",
    "    paths.append(image_path)\n",
    "    batch.append(cropped_image)\n",
    "\n",
    "    if len(batch) == BATCH_SIZE:\n",
    "        preds = classifier.predictOnBatch(batch)\n",
    "        top_probs, class_indxes = preds.max(dim=1)\n",
    "        confs = top_probs.cpu().numpy()\n",
    "        detections = [class_labels[idx] for idx in class_indxes]\n",
    "\n",
    "        batch_results = pd.DataFrame(\n",
    "            {'image': paths, 'detected_animal': detections, 'confidence': confs})\n",
    "        results = pd.concat([results, batch_results], ignore_index=True)\n",
    "        batch = []\n",
    "        paths = []\n",
    "\n",
    "if len(batch) > 0:\n",
    "    preds = classifier.predictOnBatch(batch)\n",
    "    top_probs, class_indxes = preds.max(dim=1)\n",
    "    confs = top_probs.cpu().numpy()\n",
    "    detections = [class_labels[idx] for idx in class_indxes]\n",
    "\n",
    "    batch_results = pd.DataFrame(\n",
    "        {'image': paths, 'detected_animal': detections, 'confidence': confs})\n",
    "    results = pd.concat([results, batch_results], ignore_index=True)\n",
    "\n",
    "now = datetime.now().strftime('%Y_%m_%d_%H_%M')\n",
    "results.to_csv(f'../results/deepfaune/results_deepfaune_{now}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4c5e5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>detected_animal</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../pictures/01_CZARNE/B/Lato/2/2023-07-18 02-03-54.JPG</td>\n",
       "      <td>empty</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../pictures/01_CZARNE/B/Lato/2/2023-07-18 02-06-43.JPG</td>\n",
       "      <td>empty</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../pictures/01_CZARNE/B/Lato/2/2023-07-25 18-36-14.JPG</td>\n",
       "      <td>empty</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../pictures/01_CZARNE/B/Lato/2/2023-07-26 03-47-00.JPG</td>\n",
       "      <td>empty</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../pictures/01_CZARNE/B/Lato/2/2023-07-26 03-47-13.JPG</td>\n",
       "      <td>empty</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18086</th>\n",
       "      <td>../../pictures/30_SUCHEDNIÓW/R/Zima/3/2023-02-22 17-24-47.JPG</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.983016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18087</th>\n",
       "      <td>../../pictures/30_SUCHEDNIÓW/R/Zima/3/2023-02-23 12-08-08.JPG</td>\n",
       "      <td>roe deer</td>\n",
       "      <td>0.996249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18088</th>\n",
       "      <td>../../pictures/30_SUCHEDNIÓW/R/Zima/3/2023-03-01 15-46-14.JPG</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.845402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18089</th>\n",
       "      <td>../../pictures/30_SUCHEDNIÓW/R/Zima/3/2023-03-01 20-06-01.JPG</td>\n",
       "      <td>mustelid</td>\n",
       "      <td>0.981854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18090</th>\n",
       "      <td>../../pictures/30_SUCHEDNIÓW/R/Zima/3/2023-03-03 06-56-59.JPG</td>\n",
       "      <td>fox</td>\n",
       "      <td>0.986192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18091 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               image  \\\n",
       "0          ../../pictures/01_CZARNE/B/Lato/2/2023-07-18 02-03-54.JPG   \n",
       "1          ../../pictures/01_CZARNE/B/Lato/2/2023-07-18 02-06-43.JPG   \n",
       "2          ../../pictures/01_CZARNE/B/Lato/2/2023-07-25 18-36-14.JPG   \n",
       "3          ../../pictures/01_CZARNE/B/Lato/2/2023-07-26 03-47-00.JPG   \n",
       "4          ../../pictures/01_CZARNE/B/Lato/2/2023-07-26 03-47-13.JPG   \n",
       "...                                                              ...   \n",
       "18086  ../../pictures/30_SUCHEDNIÓW/R/Zima/3/2023-02-22 17-24-47.JPG   \n",
       "18087  ../../pictures/30_SUCHEDNIÓW/R/Zima/3/2023-02-23 12-08-08.JPG   \n",
       "18088  ../../pictures/30_SUCHEDNIÓW/R/Zima/3/2023-03-01 15-46-14.JPG   \n",
       "18089  ../../pictures/30_SUCHEDNIÓW/R/Zima/3/2023-03-01 20-06-01.JPG   \n",
       "18090  ../../pictures/30_SUCHEDNIÓW/R/Zima/3/2023-03-03 06-56-59.JPG   \n",
       "\n",
       "      detected_animal  confidence  \n",
       "0               empty    0.000000  \n",
       "1               empty    0.000000  \n",
       "2               empty    0.000000  \n",
       "3               empty    0.000000  \n",
       "4               empty    0.000000  \n",
       "...               ...         ...  \n",
       "18086             fox    0.983016  \n",
       "18087        roe deer    0.996249  \n",
       "18088             fox    0.845402  \n",
       "18089        mustelid    0.981854  \n",
       "18090             fox    0.986192  \n",
       "\n",
       "[18091 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7591409",
   "metadata": {},
   "source": [
    "### Classify single animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5bab173a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using vit_large_patch14_dinov2.lvd142m with weights at models/deepfaune-vit_large_patch14_dinov2.lvd142m.v4.pt, in resolution 560x560\n",
      "CUDA available\n"
     ]
    }
   ],
   "source": [
    "classifier = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf1660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.2498e-06,  2.9331e-06,  2.8294e-06,  3.9971e-06,  7.6311e-06,  9.9209e-06,  1.6024e-06,  0.00010547,  1.4596e-05,  1.0276e-05,  1.5422e-05,   1.076e-05,  2.0871e-06,  5.1336e-06,  1.1234e-05,   1.012e-06,  3.3339e-05,  5.4318e-06,  1.3989e-06,  7.7259e-06,  4.0932e-06,  2.5115e-06,     0.99964,\n",
       "         8.8029e-07,   3.431e-06,  1.3685e-06,  1.8991e-06,  9.2729e-06,  6.2021e-06,  1.0418e-05,  1.8977e-06,  2.1094e-05,  8.4796e-07,  1.6212e-06,  1.8961e-05,  1.6373e-06,  8.7422e-06,  1.1793e-05]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropped_tensor = torch.ones((1, 3, CROP_SIZE, CROP_SIZE))\n",
    "cropped_tensor[0, :, :, :] =  classifier.preprocessImage(image)\n",
    "scores = classifier.model.predict(cropped_tensor)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3627ec79",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'species':class_labels, 'score':scores[0][:]})\n",
    "output = output[output['score'] > 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03bf0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wykryto zwierzę: lynx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(eog:16505): Gtk-WARNING **: 08:49:08.322: Theme file for DMZ-Black has no directories\n"
     ]
    }
   ],
   "source": [
    "print(f\"Animal detected: {output.loc[output['score'].idxmax(), 'species']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
