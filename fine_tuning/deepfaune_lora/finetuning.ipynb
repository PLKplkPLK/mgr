{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c74e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "%run ../../deepfaune/deepfaune_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c097e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = '../../deepfaune/models/deepfaune-vit_large_patch14_dinov2.lvd142m.v4.pt'\n",
    "model = Deepfaune(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f162dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=16, lora_alpha=32, target_modules=[\"q\", \"v\"],\n",
    "    lora_dropout=0.05, bias=\"none\", task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "# Wrap the ViT model\n",
    "model = get_peft_model(model.base_model, lora_config)\n",
    "\n",
    "# Only LoRA parameters are trainable\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop same as above\n",
    "for imgs, labels in dataloader:\n",
    "    imgs, labels = imgs.to(model.device), labels.to(model.device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(imgs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
