{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17eefc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from fine_tuning.speciesnet_head.speciesnet_polish_model import get_model, predict\n",
    "from utils.detector import Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7d8a8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ab6eb",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af551162",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, class_names = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf4fad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using deepfaune-yolov8s_960 with weights at deepfaune/models/deepfaune-yolov8s_960.pt, in resolution 960x960 on cuda\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m croppedimage, category, box, count, humanboxes = detector.bestBoxDetection(IMAGE_PATH)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m croppedimage \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m()\n\u001b[32m      9\u001b[39m predict(model, croppedimage, class_names)\n",
      "\u001b[31mValueError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "PICTURES_PATH = '../pictures/'\n",
    "PICTURE_SUBPATH = '01_CZARNE/B/Lato/3/'\n",
    "IMAGE_PATH = PICTURES_PATH + PICTURE_SUBPATH + '2023-07-19 05-18-16.JPG'\n",
    "detector = Detector(dfyolo_weights='deepfaune/models/deepfaune-yolov8s_960.pt')\n",
    "\n",
    "croppedimage, category, box, count, humanboxes = detector.bestBoxDetection(IMAGE_PATH)\n",
    "if croppedimage is None:\n",
    "    raise ValueError()\n",
    "predict(model, croppedimage, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e14486",
   "metadata": {},
   "outputs": [],
   "source": [
    "croppedimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2617c6",
   "metadata": {},
   "source": [
    "### ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "727bcd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd758178",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('deepfaune/results/results_deepfaune2025_11_05_13_58.csv', index_col=0)\n",
    "md = pd.read_csv('results/speciesnet_head/results_speciesnet_head_2025_11_21_10_03.csv', index_col=0)\n",
    "mds = pd.read_csv(r'results\\speciesnet_head\\results_square_speciesnet_head_2025_11_21_12_42.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884b9afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(8027)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.detected_animal == 'empty').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50fd50b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4435)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(md.detected_animal == 'empty').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fa788c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4435)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mds.detected_animal == 'empty').sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
