{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547a3f9e",
   "metadata": {},
   "source": [
    "Classify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4771a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from torch import tensor\n",
    "from torchvision.transforms import transforms, InterpolationMode\n",
    "\n",
    "SPECIESNET_PATH = 'models/speciesnet-pytorch-v4.0.1a-v1/'\n",
    "SPECIESNET_MODEL = SPECIESNET_PATH + 'always_crop_99710272_22x8_v12_epoch_00148.pt'\n",
    "\n",
    "LABELS_FILE = 'models/speciesnet-pytorch-v4.0.1a-v1/always_crop_99710272_22x8_v12_epoch_00148.labels.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e065e7",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d787524",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.read_csv('../megadetector_results.csv', index_col=0)\n",
    "images['image_path'] = '../' + images['image_path']\n",
    "images['bbox'] = images[\"bbox\"].apply(\n",
    "    lambda b: ast.literal_eval(b) if isinstance(b, str) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b46c1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speciesnet loaded onto cuda\n"
     ]
    }
   ],
   "source": [
    "CROP_SIZE = 480\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "with open(LABELS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    classes_labels = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = torch.load(SPECIESNET_MODEL, map_location=self.device, weights_only=False)\n",
    "        self.model.eval()\n",
    "        print(f'Speciesnet loaded onto {self.device}')\n",
    "\n",
    "        # transform image to form usable by network\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Resize(size=(CROP_SIZE, CROP_SIZE), interpolation=InterpolationMode.BICUBIC),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def predictOnBatch(self, pil_images, withsoftmax=True):\n",
    "        \"\"\"\n",
    "        pil_images: list of PIL.Image\n",
    "        returns: np.ndarray of shape (B, num_classes)\n",
    "        \"\"\"\n",
    "        # Transform all images\n",
    "        tensors = [self.transforms(im) for im in pil_images]   # list of (3, H, W)\n",
    "        batch = torch.stack(tensors).to(self.device)           # (B, 3, H, W)\n",
    "        batch = batch.permute(0, 2, 3, 1)                      # (B, H, W, 3)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(batch)\n",
    "            preds = logits.softmax(dim=1) if withsoftmax else logits\n",
    "\n",
    "        return preds.cpu()\n",
    "\n",
    "\n",
    "def crop_normalized_bbox(img: Image.Image, bbox: list[float]):\n",
    "    \"\"\"\n",
    "    img: PIL.Image opened image\n",
    "    bbox: list [x, y, w, h], normalized 0-1\n",
    "    returns cropped PIL.Image\n",
    "    \"\"\"\n",
    "    W, H = img.size\n",
    "    x, y, w, h = bbox\n",
    "\n",
    "    left   = int(x * W)\n",
    "    top    = int(y * H)\n",
    "    right  = int((x + w) * W)\n",
    "    bottom = int((y + h) * H)\n",
    "\n",
    "    return img.crop((left, top, right, bottom))\n",
    "\n",
    "classifier = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128ddc57",
   "metadata": {},
   "source": [
    "### The loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1dd397c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fe2d534b4a4021842d7813d10c5c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/1/2022-11-18 05-58-30.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/1/2022-11-18 05-59-31.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/1/2022-11-18 06-08-54.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/1/2022-11-18 06-11-45.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/1/2022-11-18 06-11-53.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-20 20-37-25.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-21 21-58-04.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-23 20-44-24.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-24 19-47-26.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-24 20-03-00.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-24 21-01-18.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-24 21-07-20.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-24 21-11-14.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/10_ŁUPKÓW/B/Późna jesień/2/2022-11-24 21-23-57.JPG: image file is truncated (18 bytes not processed)\n",
      "Error in image ../../pictures/10_ŁUPKÓW/R/Późna jesień/1/2022-11-14 22-12-20.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/11_ZUBEŃSKO/B/Wczesna jesień/3/2022-10-02 21-42-15.JPG: broken data stream when reading image file\n",
      "Error in image ../../pictures/16_HUTA_KOMOROWSKA/B/Lato/1/2023-07-08 08-12-33.JPG: image file is truncated (22 bytes not processed)\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({'image': [], 'detected_animal': [], 'confidence': []})\n",
    "batch = []\n",
    "paths = []\n",
    "\n",
    "for _, row in tqdm(images.iterrows(), total=len(images)):\n",
    "    image_path = row['image_path']\n",
    "\n",
    "    category = row['category']\n",
    "    if category != 1:\n",
    "        results.loc[len(results)] = [image_path, 'empty', 0]\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        cropped_image = crop_normalized_bbox(image, row['bbox'])\n",
    "    except Exception as e:\n",
    "        print(f'Error in image {image_path}: {e}')\n",
    "        continue\n",
    "\n",
    "    paths.append(image_path)\n",
    "    batch.append(cropped_image)\n",
    "\n",
    "    if len(batch) == BATCH_SIZE:\n",
    "        preds = classifier.predictOnBatch(batch)\n",
    "        top_probs, class_indxes = preds.max(dim=1)\n",
    "        confs = top_probs.cpu().numpy()\n",
    "        detections = [classes_labels[idx].split(';')[-1] for idx in class_indxes]\n",
    "\n",
    "        batch_results = pd.DataFrame(\n",
    "            {'image': paths, 'detected_animal': detections, 'confidence': confs})\n",
    "        results = pd.concat([results, batch_results], ignore_index=True)\n",
    "        batch = []\n",
    "        paths = []\n",
    "\n",
    "if len(batch) > 0:\n",
    "    preds = classifier.predictOnBatch(batch)\n",
    "    top_probs, class_indxes = preds.max(dim=1)\n",
    "    confs = top_probs.cpu().numpy()\n",
    "    detections = [classes_labels[idx].split(';')[-1] for idx in class_indxes]\n",
    "\n",
    "    batch_results = pd.DataFrame(\n",
    "        {'image': paths, 'detected_animal': detections, 'confidence': confs})\n",
    "    results = pd.concat([results, batch_results], ignore_index=True)\n",
    "\n",
    "now = datetime.now().strftime('%Y_%m_%d_%H_%M')\n",
    "results.to_csv('../results/speciesnet/results_speciesnet_' + now + '.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
